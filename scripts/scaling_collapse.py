import sys, os
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

# 1. PYTHON: Environment setup to ensure the script can find your 'src' folder.
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
from src.plotting import set_publication_style

# -------------------- PARAMETERS --------------------
# 2. DATA: Ensure this matches the master CSV generated by your data_merger script.
INPUT_FILE = "results/data/research_run_L14_J20.5_N60_k300.csv"

# 3. PHYSICS: Defining the range of Wc we want to test. 
#    We use a list here so the main loop can iterate over them.
J2_TARGET = 0.5
WC_TRIALS = [3.1] 
NU_FIXED = 1.0  # We hold nu constant to find the best Wc first.
# ----------------------------------------------------

def run_scaling_analysis(wc, nu):
    """
    Performs the Finite Size Scaling (FSS) transformation for a specific Wc and Nu.
    """
    if not os.path.exists(INPUT_FILE):
        print(f"Data not found at {INPUT_FILE}")
        return

    # 4. PYTHON: Loading data and filtering for the chaotic sector (J2=0.5).
    df = pd.read_csv(INPUT_FILE)
    df = df[df["J2"] == J2_TARGET]
    
    set_publication_style()
    plt.figure(figsize=(7, 5))

    # 5. PHYSICS: Iterating through each system size L.
    #    The scaling hypothesis states that r = f((W - Wc) * L^(1/nu)).
    for L in sorted(df["L"].unique()):
        sub = df[df["L"] == L].sort_values("W")
        
        # 6. MATH: Applying the scaling transform to the X-axis.
        #    This shifts the transition point to 0 and stretches/shrinks L-curves.
        x_scaled = (sub["W"] - wc) * (L ** (1.0 / nu))
        
        # 7. RESEARCH GRADE: Plotting with Error Bars (SEM).
        #    Crucial for checking if the collapse is statistically significant.
        plt.errorbar(
            x_scaled, sub["r_mean"], yerr=sub["r_sem"],
            marker='o', markersize=4, capsize=2, label=f"$L={L}$",
            ls='-', lw=1, alpha=0.8
        )

    # 8. BENCHMARKS: Adding the RMT limits for GOE and Poisson.
    plt.axhline(0.536, ls="--", color="gray", alpha=0.5, label="GOE")
    plt.axhline(0.386, ls=":", color="gray", alpha=0.5, label="Poisson")
    plt.axvline(0, color='black', lw=0.8, alpha=0.3) # Marks the trial Wc

    # 9. STYLE: Formatting with LaTeX for journal-ready appearance.
    plt.xlabel(r"Scaled Disorder $(W - W_c)L^{1/\nu}$")
    plt.ylabel(r"Average gap ratio $\langle r \rangle$")
    plt.title(r"Scaling Collapse ($W_c=%.1f, \nu=%.1f$)" % (wc, nu))
    plt.legend(frameon=False, loc="best", fontsize=9)
    plt.tight_layout()
    
    # 10. FILE I/O: Saving each plot with the Wc value in the filename.
    #     This prevents the script from overwriting the previous graph.
    save_dir = "results/figures/test/scans"
    os.makedirs(save_dir, exist_ok=True)
    save_path = f"{save_dir}/collapse_J2_{J2_TARGET}_Wc_{wc:.2f}.pdf"
    
    plt.savefig(save_path)
    plt.show()
    plt.close() # Closes the figure to free up memory for the next loop
    print(f"âœ… Saved: {save_path}")

if __name__ == "__main__":
    # 11. THE LOOP: This is how you run it for all different values.
    print(f"Starting batch scaling scan for J2={J2_TARGET}...")
    for wc_val in WC_TRIALS:
        run_scaling_analysis(wc=wc_val, nu=NU_FIXED)
    print("Done. Check results/figures/scans/ for all PDFs.")